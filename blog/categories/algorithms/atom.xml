<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: algorithms | Cheraq.com]]></title>
  <link href="http://cheraq.com/blog/categories/algorithms/atom.xml" rel="self"/>
  <link href="http://cheraq.com/"/>
  <updated>2013-05-27T12:34:42+04:00</updated>
  <id>http://cheraq.com/</id>
  <author>
    <name><![CDATA[Mohammad J. Fathinia]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Algorithms: What? Why? When? How?]]></title>
    <link href="http://cheraq.com/blog/2011/07/05/algorithms-what-why-when-how/"/>
    <updated>2011-07-05T19:35:00+04:00</updated>
    <id>http://cheraq.com/blog/2011/07/05/algorithms-what-why-when-how</id>
    <content type="html"><![CDATA[<p>We&#8217;ve heard about algorithms a lot. In this short article, I am going to a little bit talk about algorithms, their importance, etc. which will be the first post in my Algorithms series. If you follow the series, you will get familiar with different type of algorithms, old and classic ones, or new and heuristic ones. Just follow the series.</p>

<h2>What is an algorithm?</h2>

<p>An algorithm in simple language is a finite set of instructions for calculating a function. For example we are looking for a file in a folder, what we might do is, we start from beginning of the list, check each and every file until we find the file we want or reaching to the end of the list. This is an algorithm.</p>

<h2>Why we should learn them?</h2>

<p>Algorithms are actually ways to solve problems; but they are not the solution. By learning algorithms you will find methods that help you in solving problems. It is like [Data Structure] (http://en.wikipedia.org/wiki/Data_structure). If we consider data structure as a tool, algorithms will be manual that helps us to learn how to use those tools to do desired task.</p>

<h2>When shall I use specific algorithm?</h2>

<p>The solution and algorithm you choose for any given problem, depends to:</p>

<ul>
<li>The way you are looking at the problem and visualizing it</li>
<li>Run Time/Space limits</li>
<li>Input Size</li>
</ul>


<p>These are only key factors. There are lots of other factors that might play a key role in selecting an algorithm, such as data structure, etc. Maybe the last two factors are obvious, but let's see how the first factor might play a key role. Consider the classic 8-Queen problem. In this problem we want to place 8 queens in a 8x8 chessboard in a way that none of them could attack others.</p>

<p>Let's say we are going to solve it by placing one queen at a time in a way that it will not be able to attack previous queens we have placed. Once we reached to a place that we cannot find a place for this queen, we will return back and move the previous queen to another cell and then continue, until we reach to a result. In this way we are using <strong>backtracking</strong> to solve the issue.</p>

<p>But there is another way to look at the problem. Let's say we will place 8 queens in 8 rows randomly. Then we start to move queens in a way to minimize the number of queens that can attach each other. Now we have turned the problem into <strong>optimization problem</strong>. So as you can see, they way you are understanding and visualizing a problem will play a key role in solving it and finding algorithm.</p>

<h2>How we can compare two algorithms?</h2>

<p>Well, if there are different algorithms to solve a problem, then there should be some ways to compare them (I&#8217;m genius). We usually compare two algorithms based on their <strong>time</strong> and <strong>space complexity</strong>. Time and space complexity are not indicating the exact amount of time/space are required to solve a problem; instead they indicate how the time/space requirements will grow when the problem size grows. Since we want to study how the time/space requirements will grow, then we don't need to consider the exact equation of time/space complexity; We can just consider the biggest factor. Let's see this in below simple example.</p>

<h3>Finding an item in an ordered list</h3>

<p>Let's say we have an ordered list of numbers with size <strong><em>n</em></strong> and we want to see if this list contains number <strong><em>x</em></strong> or not. We can use below ways to search for <strong><em>x</em></strong>:</p>

<p><strong>Algorithm 1:</strong> We will start from first item and compare it with <strong><em>x</em></strong>: if it is equal, then list contains this number, otherwise, we will go to next item until we reach end of the list or find <strong><em>x</em></strong> in the list.</p>

<p><strong>Algorithm 2 (Binary Search):</strong> We compare <strong><em>x</em></strong> with the middle item of the list. If <strong><em>x</em></strong> is larger than middle item, then we should be able to find it in the second half of the list and we can ignore the first one and vice versa. Once we find out on which part of the list we have to search for <strong><em>x</em></strong>, then we repeat the same step, compare <strong><em>x</em></strong> with the middle item of this new list (first/second half). We continue this until we find <strong><em>x</em></strong> or reaching to a list with size <strong><em>1</em></strong>.</p>

<p>As you can see, we usually using second algorithm to find items in ordered list. Now let's see how we can compare the time complexity of these two algorithms. When we want to estimate time complexity, we count how many times a key action or block of actions will be repeated. Like in our example, how many times we should perform comparison to find out given list contains <strong><em>x</em></strong> or not. In order to eliminate role of <strong><em>x</em></strong> in our estimation, we consider the <strong>worth-case scenario</strong> such as list does not contain x.</p>

<p>In the algorithm 1, we need to do comparison <strong><em>n</em></strong> times in the worth-case (which is obvious). But what about algorithm 2? The answer is <strong><em>log n</em></strong> (when we are using <strong><em>log</em></strong>, we usually mean <strong><em>log</em></strong> in base <strong><em>2</em></strong>). If you check the algorithm, you will see at each step we will divide list into half, so the list size will change like: <strong><em>n</em></strong>, <strong><em>n/2</em></strong>, <strong><em>n/4</em></strong>, <strong><em>n/8</em></strong>, <strong><em>n/16</em></strong>, &hellip; . So in the worth-case we will continue up to <strong><em>log n</em></strong>. When we want to denote the time/space complexity, we usually use <em>big O</em>, and we will show it as <strong><em>O(n)</em></strong> or <strong><em>O(log n)</em></strong>. This mean we are just considering the most significant factor and we are neglecting the others. For example if you algorithms time complexity is polynomial like <strong><em>( n<sup>x</sup> + n )</em></strong>, then we can say the time complexity is equal to <strong><em>O( n<sup>x</sup> )</em></strong>.</p>

<h2>Conclusion</h2>

<p>Finding proper algorithm for a given problem could be challenging. Learning more algorithms will give us better vision and understanding, and we will be able to analyze problem from different aspects and find different algorithms to solve the problem. Time/space complexity enables us to compare algorithms and choose the best algorithm based on input size and other limitations.</p>

<p>This was an introduction about algorithms. In next articles we will see different type of algorithms and their pros and cons.  Also we will learn how to calculate time/space complexity and combine different algorithms with some heuristic functions in order to reduce complexity.</p>
]]></content>
  </entry>
  
</feed>
